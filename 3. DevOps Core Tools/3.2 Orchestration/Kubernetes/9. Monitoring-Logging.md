---
title: "‚Ä¢ Monitoring & Logging"
parent: "‚Ä¢ Kubernetes"
grand_parent: 3. DevOps Core Tools
nav_order: 9
has_children: true
---

Topics:

Metrics server, cAdvisor

Prometheus, Grafana

Logging (Fluentd, Loki, ELK)

Dashboard setup


=======================================

# üîç Kubernetes Observability ‚Äì Complete Notes

Observability helps us **understand what is happening inside a Kubernetes cluster** by collecting **metrics, logs, and traces**.

In simple words:

> **Observability = Metrics + Logs + Traces**

---

## üìå What is Observability?

Observability answers **three key questions**:

| Question                      | Aspect               | Tools                         |
| ----------------------------- | -------------------- | ----------------------------- |
| **What is happening?**        | Metrics (Monitoring) | Prometheus, Grafana           |
| **Why did it happen?**        | Logs (Logging)       | Loki, Promtail, Elasticsearch |
| **How did the request flow?** | Traces (Tracing)     | Jaeger, OpenTelemetry         |

---

## üß† Why Observability is Important?

In Kubernetes:

* Pods are **ephemeral** (can die anytime)
* Applications are **distributed**
* Debugging via SSH is not reliable

So we need:

* Centralized monitoring
* Centralized logging
* Distributed tracing

---

# üìä 1. Metrics (Monitoring)

### üîπ What are Metrics?

Metrics are **numerical data points over time**, such as:

* CPU usage
* Memory usage
* Pod count
* Request rate
* Error rate

---

## üî• Prometheus

**Prometheus** is the most popular **monitoring system** for Kubernetes.

### Key Features:

* **Time-Series Database**
* **Pull-based (scraping)** model
* **PromQL** query language
* Native Kubernetes integration

### Prometheus Architecture:

| Component      | Description                            |
| -------------- | -------------------------------------- |
| Time Series DB | Stores metrics with timestamp          |
| Scraper        | Pulls metrics from targets             |
| PromQL         | Query language                         |
| Targets        | Nodes, Pods, Services                  |
| Alertmanager   | Sends alerts (Slack, Email, PagerDuty) |

---

### Prometheus Scraping Flow:

```
Application ‚Üí /metrics endpoint
Prometheus ‚Üí scrapes metrics
Metrics ‚Üí stored in TSDB
Grafana ‚Üí visualizes metrics
```

---

## üìà Grafana

**Grafana** is a **visualization layer**.

### What Grafana Does:

* Dashboards
* Graphs
* Alerts
* Multiple data sources

### Supported Data Sources:

* Prometheus
* Loki
* Elasticsearch
* InfluxDB

> Grafana does **not store data**, it only **visualizes** it.

---

# ü™µ 2. Logs (Logging)

### üîπ What are Logs?

Logs are **text-based records**:

* Errors
* Warnings
* Application messages

Example:

```text
ERROR: Database connection failed
```

---

## üî• Loki (Logging)

**Loki** is a **log aggregation system by Grafana Labs**.

### Why Loki?

* Designed for Kubernetes
* Uses labels (same as Prometheus)
* Lightweight compared to ELK

### Loki Stack:

| Component | Role              |
| --------- | ----------------- |
| Loki      | Log storage       |
| Promtail  | Log collector     |
| Grafana   | Log visualization |

---

### Logging Flow:

```
Pod logs ‚Üí Promtail ‚Üí Loki ‚Üí Grafana
```

---

# üîÅ 3. Traces (Distributed Tracing)

### üîπ What are Traces?

Traces show **request flow across services**.

Example:

```
Frontend ‚Üí Backend ‚Üí Database
```

---

## üî• Jaeger

Jaeger helps:

* Find latency issues
* Debug microservices
* Understand request lifecycle

---

## üî• OpenTelemetry (OTel)

**OpenTelemetry** is a **standard** for:

* Metrics
* Logs
* Traces

It can export data to:

* Prometheus
* Jaeger
* Grafana Tempo

> OpenTelemetry is **vendor-neutral** and future-proof.

---

# üõ† Installing Prometheus + Grafana using Helm

## Step 1Ô∏è‚É£ Install Helm

(Already covered earlier)

---

## Step 2Ô∏è‚É£ Add Prometheus Community Repo

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo list
helm repo update
```

---

## Step 3Ô∏è‚É£ Install kube-prometheus-stack

```bash
helm install prometheus-stack prometheus-community/kube-prometheus-stack \
--namespace monitoring --create-namespace \
--set prometheus.service.type=NodePort \
--set prometheus.service.nodePort=30000 \
--set grafana.service.type=NodePort \
--set grafana.service.nodePort=31000
```

---

## Step 4Ô∏è‚É£ Verify Installation

```bash
kubectl get pods -n monitoring
kubectl get svc -n monitoring
```

---

### üîç Important Components Explained

| Component          | Purpose                            |
| ------------------ | ---------------------------------- |
| node-exporter      | Collects node-level metrics        |
| kube-state-metrics | Collects Kubernetes object metrics |
| prometheus         | Stores metrics                     |
| grafana            | Visualization                      |

> **node-exporter runs on each node**, so you see multiple pods.

---

# üåê Access Prometheus & Grafana

## Prometheus Port Forward

```bash
kubectl port-forward svc/prometheus-stack-kube-prometheus-prometheus 9090:9090 -n monitoring --address=0.0.0.0
```

Access:

```
http://localhost:9090
```

---

## Grafana Port Forward

```bash
kubectl port-forward svc/prometheus-stack-grafana 3000:80 -n monitoring --address=0.0.0.0
```

Access:

```
http://localhost:3000
```

---

## Grafana Login

### Username:

```
admin
```

### Get Password:

```bash
kubectl get secret prometheus-stack-grafana -n monitoring \
-o jsonpath="{.data.admin-password}" | base64 --decode
```

---

# üß† Interview Important Points (Must Remember)

* Prometheus is **pull-based**
* Grafana is **only visualization**
* Loki is **log aggregation**
* Jaeger is **distributed tracing**
* kube-state-metrics ‚â† node-exporter
* Observability = Metrics + Logs + Traces

---

# üìå Real-World Example

| Issue        | Tool          |
| ------------ | ------------- |
| Pod CPU high | Prometheus    |
| App crashed  | Loki          |
| API slow     | Jaeger        |
| Node issue   | node-exporter |



=============================

---

# üß† Interview Q&A ‚Äì Kubernetes Observability

## 1Ô∏è‚É£ What is Observability?

**Observability** is the ability to understand the **internal state of a system** using:

* **Metrics** (what is happening)
* **Logs** (why it happened)
* **Traces** (how it happened)

üëâ *Observability = Metrics + Logs + Traces*

---

## 2Ô∏è‚É£ Difference between Monitoring and Observability?

| Monitoring                   | Observability                |
| ---------------------------- | ---------------------------- |
| Tells **something is wrong** | Tells **what, why, and how** |
| Predefined alerts            | Deep debugging capability    |
| Reactive                     | Proactive + Reactive         |

---

## 3Ô∏è‚É£ What are Metrics?

Metrics are **numerical time-series data**, like:

* CPU usage
* Memory usage
* Pod count
* Request rate
* Error rate

Example:

```
cpu_usage{pod="nginx"} = 120m
```

---

## 4Ô∏è‚É£ What is Prometheus?

**Prometheus** is a **monitoring & alerting system** used mainly with Kubernetes.

### Key Points (Interview Favorite):

* Pull-based (scrapes `/metrics`)
* Time-Series Database
* Uses **PromQL**
* Kubernetes-native
* Stores metrics, not logs

---

## 5Ô∏è‚É£ What is Grafana?

**Grafana** is a **visualization tool**.

* Creates dashboards
* Reads data from Prometheus, Loki, Elasticsearch
* Does NOT store data

üëâ *Prometheus collects data, Grafana shows it.*

---

## 6Ô∏è‚É£ What is Logging?

Logs are **text-based application records**, such as:

* Errors
* Warnings
* Debug messages

Used to answer: **Why did this fail?**

---

## 7Ô∏è‚É£ What is Loki?

**Loki** is a **log aggregation system** designed for Kubernetes.

### Why Loki over ELK?

* Lightweight
* Uses labels like Prometheus
* Cost-effective
* Tight Grafana integration

---

## 8Ô∏è‚É£ What is Promtail?

**Promtail** is a log collector:

* Runs on nodes
* Reads container logs
* Pushes logs to Loki

---

## 9Ô∏è‚É£ What is Tracing?

Tracing tracks **a single request** across multiple services.

Example:

```
Frontend ‚Üí Backend ‚Üí Auth ‚Üí DB
```

Helps identify:

* Latency issues
* Bottlenecks
* Service failures

---

## üîü What is Jaeger?

**Jaeger** is a **distributed tracing system**.

Used for:

* Microservices debugging
* Performance optimization
* Request flow analysis

---

## 1Ô∏è‚É£1Ô∏è‚É£ What is OpenTelemetry?

**OpenTelemetry (OTel)** is a **standard framework** for:

* Metrics
* Logs
* Traces

Vendor-neutral and future-proof.

---

## 1Ô∏è‚É£2Ô∏è‚É£ What is node-exporter?

* Collects **node-level metrics**
* CPU, Memory, Disk, Network
* Runs as **DaemonSet**

---

## 1Ô∏è‚É£3Ô∏è‚É£ What is kube-state-metrics?

* Exposes **Kubernetes object metrics**
* Pods, Deployments, Nodes, HPA
* Reads from Kubernetes API Server

---

## 1Ô∏è‚É£4Ô∏è‚É£ Difference: node-exporter vs kube-state-metrics

| node-exporter    | kube-state-metrics      |
| ---------------- | ----------------------- |
| Node metrics     | Kubernetes object state |
| OS-level         | API-level               |
| Hardware focused | Cluster focused         |

---

## 1Ô∏è‚É£5Ô∏è‚É£ Real-World Debugging Mapping

| Issue            | Tool                 |
| ---------------- | -------------------- |
| Pod restart loop | Logs (Loki)          |
| High CPU         | Metrics (Prometheus) |
| Slow API         | Traces (Jaeger)      |
| Node failure     | node-exporter        |

---

# üìä Prometheus Stack ‚Äì Architecture Diagram

![Image](https://cdn.prod.website-files.com/681e366f54a6e3ce87159ca4/6877c683c0a47068f5e6609c_Blog-Kubernetes-Monitoring-with-Prometheus-4-Architecture-Overview.png?utm_source=chatgpt.com)

![Image](https://www.apptio.com/wp-content/uploads/kube-prometheus-1.png?utm_source=chatgpt.com)

![Image](https://miro.medium.com/v2/resize%3Afit%3A1400/1%2A0vXfW4gPKFcwC2alH2qMyA.gif?utm_source=chatgpt.com)

---

## üîÅ Prometheus Stack ‚Äì Text Architecture (GitHub Friendly)

```
+-------------------+
|   Kubernetes Pod  |
|  (/metrics endpoint)
+---------+---------+
          |
          v
+-------------------+
|  Prometheus       |
|  - Scraper        |
|  - TSDB           |
|  - PromQL         |
+---------+---------+
          |
          v
+-------------------+
|   Grafana         |
|  - Dashboards     |
|  - Alerts         |
+-------------------+

Node Metrics:
Node ‚Üí node-exporter ‚Üí Prometheus

K8s State:
API Server ‚Üí kube-state-metrics ‚Üí Prometheus

Logs:
Pod Logs ‚Üí Promtail ‚Üí Loki ‚Üí Grafana

Traces:
Application ‚Üí OpenTelemetry ‚Üí Jaeger
```

---

## üéØ Interview One-Line Summary (Very Important)

* **Prometheus** ‚Üí metrics collection
* **Grafana** ‚Üí visualization
* **Loki** ‚Üí logs
* **Promtail** ‚Üí log collector
* **Jaeger** ‚Üí tracing
* **OpenTelemetry** ‚Üí observability standard



============================================

---

# üß† Advanced Scenario-Based Interview Questions

## (Kubernetes Observability ‚Ä¢ Monitoring ‚Ä¢ Troubleshooting)

---

## 1Ô∏è‚É£ Pod is running but application is not accessible. How will you debug?

### üîç Step-by-step approach:

1. **Check Pod status**

```bash
kubectl get pods -n <ns>
```

2. **Check logs**

```bash
kubectl logs <pod> -n <ns>
```

3. **Check readiness probe**

```bash
kubectl describe pod <pod>
```

4. **Check Service**

```bash
kubectl get svc -n <ns>
kubectl describe svc <svc>
```

5. **Check Endpoints**

```bash
kubectl get endpoints <svc>
```

6. **Ingress / NetworkPolicy (if used)**

### üéØ Interview Answer:

> I check logs, readiness probe, service endpoints, and ingress rules. If readiness fails, traffic will not reach the pod even if it is running.

---

## 2Ô∏è‚É£ CPU usage is high but HPA is not scaling. Why?

### Possible Reasons:

* Metrics Server not running
* Resource requests not defined
* Wrong metric threshold
* Metrics delay

### Debug:

```bash
kubectl get hpa
kubectl describe hpa
kubectl top pods
```

### üéØ Answer:

> HPA depends on Metrics Server and resource requests. If requests are missing or metrics are unavailable, autoscaling will not work.

---

## 3Ô∏è‚É£ Metrics Server is installed but `kubectl top` is not working.

### Root Causes:

* TLS issue with kubelet
* Metrics Server flags missing

### Fix:

```yaml
--kubelet-insecure-tls
--kubelet-preferred-address-types=InternalIP
```

### üéØ Answer:

> Metrics Server could not communicate securely with kubelet. Adding insecure TLS flags resolves it in local clusters like Kind or Minikube.

---

## 4Ô∏è‚É£ Node-exporter shows 4 pods. Why?

### Reason:

* node-exporter runs as **DaemonSet**
* One pod per node

### üéØ Answer:

> node-exporter runs on every node to collect node-level metrics. If there are 4 nodes, 4 pods will run.

---

## 5Ô∏è‚É£ Pod restarts again and again. How do you identify the issue?

### Steps:

1. Check restart count

```bash
kubectl get pods
```

2. Check previous logs

```bash
kubectl logs <pod> --previous
```

3. Check liveness probe

```bash
kubectl describe pod <pod>
```

### üéØ Answer:

> I check container logs, previous logs, and liveness probe. Most restart loops are caused by probe misconfiguration or application crashes.

---

## 6Ô∏è‚É£ Application is slow. CPU and memory look normal. What next?

### Use Tracing:

* Jaeger
* OpenTelemetry

### Check:

* Request latency
* Downstream service delay
* Database calls

### üéØ Answer:

> When metrics are normal, I use distributed tracing to identify slow service calls or network latency.

---

## 7Ô∏è‚É£ Logs are missing for some pods. Why?

### Reasons:

* Pod restarted and logs rotated
* Promtail not running
* Wrong log path
* Pod crashed before logs collected

### üéØ Answer:

> I check Promtail status, log paths, and whether pods restarted before logs were scraped.

---

## 8Ô∏è‚É£ Difference between Prometheus and ELK stack?

| Prometheus  | ELK              |
| ----------- | ---------------- |
| Metrics     | Logs             |
| Pull-based  | Push-based       |
| Lightweight | Heavy            |
| Time-series | Full-text search |

### üéØ Answer:

> Prometheus is best for metrics and alerting, ELK is used for log analysis and searching.

---

## 9Ô∏è‚É£ How do you monitor Kubernetes objects like Deployments and HPA?

### Tool:

* **kube-state-metrics**

### üéØ Answer:

> kube-state-metrics exposes Kubernetes object states like replicas, pod status, and HPA metrics to Prometheus.

---

## üîü Production Alert fires but everything looks normal. What could be wrong?

### Possible Causes:

* Alert threshold too aggressive
* Alert based on short spikes
* Missing `for:` condition

### üéØ Answer:

> I tune alert thresholds and use `for:` duration to avoid false positives caused by temporary spikes.

---

## 1Ô∏è‚É£1Ô∏è‚É£ How do you secure Prometheus and Grafana?

### Best Practices:

* RBAC
* NetworkPolicies
* Authentication (OIDC)
* TLS
* Secrets encryption

### üéØ Answer:

> In production, Prometheus and Grafana must be secured using RBAC, authentication, TLS, and restricted network access.

---

## 1Ô∏è‚É£2Ô∏è‚É£ What happens if Prometheus pod restarts?

### Answer:

* Data stored locally ‚Üí lost (unless PV used)
* Alerts reset temporarily

### üéØ Answer:

> Prometheus should use PersistentVolume in production to avoid metric loss on restart.

---

## 1Ô∏è‚É£3Ô∏è‚É£ How do you monitor multi-cluster Kubernetes?

### Approaches:

* Central Prometheus
* Thanos
* Cortex
* Grafana Cloud

### üéØ Answer:

> For multi-cluster observability, I use Thanos or Cortex to aggregate metrics from multiple clusters.

---

## 1Ô∏è‚É£4Ô∏è‚É£ How do you reduce monitoring cost?

### Techniques:

* Reduce metric cardinality
* Drop unused labels
* Increase scrape interval
* Retention tuning

### üéØ Answer:

> High-cardinality metrics increase cost. I optimize labels, retention, and scrape frequency.

---

## 1Ô∏è‚É£5Ô∏è‚É£ One-Line Interview Killer Answer üí£

> *‚ÄúObservability helps me detect issues early using metrics, understand failures using logs, and trace performance problems across microservices using distributed tracing.‚Äù*

---