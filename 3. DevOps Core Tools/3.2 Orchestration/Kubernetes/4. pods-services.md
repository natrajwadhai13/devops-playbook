---
title: "‚Ä¢ Pods-Services"
parent: "‚Ä¢ Kubernetes"
grand_parent: "‚Ä¢ 3.2 Orchestration"
great_grand_parent: 3. DevOps Core Tools
nav_order: 4
has_children: true
---

# Pods & Services

- Pod definition
- ClusterIP, NodePort, LoadBalancer


-----------------------------------

Kubernetes Notes

---

## üëâ Overview ‚Äî What you‚Äôll learn

Short theory + practical commands for:

* Setting up clusters (kind, minikube, kubeadm, EKS/GKE)
* Creating Namespaces, Pods, Deployments, ReplicaSets, DaemonSets
* Jobs & CronJobs
* Common errors, fixes, and interview talking points

Keep these mental checkpoints when explaining in interviews: **purpose**, **how it works**, **example command**, **use-case**.

---

## Step 1 ‚Äî Software installation & options (theory + why)

**Goal:** know the tools companies use and why.

* **Docker** ‚Äî container runtime (use containerd/CRI-O in prod). Needed for local clusters.
* **Kubernetes** ‚Äî orchestration system (control-plane + worker nodes).
* **Local / learning tools**

  * **kind** ‚Äî Kubernetes-in-Docker, great for multi-node test clusters and CI.
  * **minikube** ‚Äî single-node local cluster (easy for demos).
  * **k3s** / **microk8s** ‚Äî lightweight distros for edge/dev.
* **Production & managed**

  * **kubeadm** ‚Äî bootstrap production-ready clusters (on VMs / on-prem).
  * **EKS (AWS)**, **GKE (Google Cloud)**, **AKS (Azure)** ‚Äî managed K8s (control plane managed for you).

**Interview points:** explain where you would use each tool (local dev vs. prod vs. cloud-managed).

---

## Step 2 ‚Äî Create a Kind cluster (example + tips)

**What is kind?**
A tool to run real Kubernetes clusters in Docker containers. Useful to simulate multi-node clusters locally.

**Kind config (example)** ‚Äî `config.yml`

```yaml
# Multi-node (1 control-plane + 3 workers) Kind cluster config
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
    image: kindest/node:v1.31.2

  - role: worker
    image: kindest/node:v1.31.2

  - role: worker
    image: kindest/node:v1.31.2

  - role: worker
    image: kindest/node:v1.31.2
    extraPortMappings:
      - containerPort: 80
        hostPort: 80
        protocol: TCP
      - containerPort: 443
        hostPort: 443
        protocol: TCP
```

**Create the cluster**

```bash
sudo kind create cluster --name=tws-cluster --config=config.yml
```

**Verify**

```bash
sudo kubectl cluster-info --context kind-tws-cluster
sudo kubectl get nodes
```

**Common Kind tips**

* Use `--config` to create multiple workers.
* `extraPortMappings` allows exposing host ports (80/443) to a node for testing Ingress.

---

## Troubleshooting (common errors + fixes)

### Error: permission denied connecting to Docker socket

```
permission denied while trying to connect to the docker API at unix:///var/run/docker.sock
```

**Fix**

```bash
sudo usermod -aG docker $USER
newgrp docker
# then re-run kind command (or log out & in)
```

### Error: RSRC_INSUFFICIENT_CORES ‚Äî Docker has < 2 CPUs

Kubernetes needs at least 2 CPUs (kind/minikube constraints).
**Check Docker limits**

```bash
docker info | grep -i cpu
```

**Workaround** ‚Äî adjust Docker daemon CPU limits (or Docker Desktop settings):

```json
# /etc/docker/daemon.json
{
  "default-runtime": "runc",
  "runtimes": { "runc": { "path": "runc" } },
  "cpu-period": 100000,
  "cpu-quota": 200000
}
```

Then:

```bash
sudo systemctl restart docker
# Retry minikube or kind
minikube start --driver=docker
```

---

## Step 3 ‚Äî Kubernetes basics: Namespace ‚Üí Pod ‚Üí Deployment ‚Üí Service (theory + commands)

### Namespaces (theory)

* Logical partitions within a cluster (e.g., `dev`, `test`, `prod`).
* Useful for multi-team isolation, resource quotas, RBAC scoping.

**Create namespace**

```bash
kubectl create ns nginx
kubectl get ns
kubectl delete ns nginx
```

---

### Pods (theory)

* **Smallest deployable unit** ‚Äî one or more containers that share network & storage.
* Imperative vs declarative creation.

**Imperative (one-off)**

```bash
kubectl run nginx --image=nginx
kubectl get pods
kubectl delete pod nginx
```

**In a namespace**

```bash
kubectl run nginx -n nginx --image=nginx
kubectl get pods -n nginx
```

**Declarative (manifest)** ‚Äî `pod.yml`

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  namespace: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
```

**Apply / verify**

```bash
kubectl apply -f namespace.yml   # namespace manifest (if not created)
kubectl apply -f pod.yml
kubectl get pod -n nginx
kubectl exec -it nginx-pod -n nginx -- bash
curl 127.0.0.1
kubectl describe pod/nginx-pod -n nginx
kubectl delete -f pod.yml
```

**Interview tip:** describe difference between Pod restartPolicy values and how containers share network namespace.

---

## Step 4 ‚Äî Deployments (theory + manifest)

### Theory

* **Deployment** manages ReplicaSets and Pods.
* Provides declarative updates, rolling updates, rollbacks, scaling.

**Deployment manifest** ‚Äî `deployment.yml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

**Commands**

```bash
kubectl apply -f deployment.yml
kubectl get deployment -n nginx
kubectl get pods -n nginx
kubectl get pods -n nginx -o wide    # see node placement
kubectl scale deployment/nginx-deployment -n nginx --replicas=5
kubectl set image deployment/nginx-deployment nginx=nginx:1.29.0 -n nginx  # rolling update
kubectl rollout undo deployment/nginx-deployment -n nginx  # rollback
kubectl delete -f deployment.yml
```

**Common error**

* `no matches for kind "Deploymeent" in version "apps/v1"` ‚Üí Typo in `kind` or invalid API version. Use `kind: Deployment` and `apiVersion: apps/v1`.

**Interview tip:** explain how Deployment ‚Üí ReplicaSet ‚Üí Pods relationship works, and how rolling updates are handled (maxSurge / maxUnavailable).

---

## Step 5 ‚Äî ReplicaSet (theory + manifest)

### Theory

* ReplicaSet ensures a specified number of pod replicas are running.
* Usually controlled by Deployments; rarely created directly in production.

**ReplicaSet manifest** ‚Äî `replicaset.yml`

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicasets
  namespace: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

**Commands**

```bash
kubectl apply -f replicaset.yml
kubectl get replicasets -n nginx
kubectl delete -f replicaset.yml
```

**Interview tip:** explain why Deployments are preferred (adds update management).

---

## Step 6 ‚Äî DaemonSet (theory + manifest)

### Theory

* DaemonSet runs one pod **on every (or selected) node**.
* Use-cases: logging agents (Fluentd), monitoring agents (Prometheus Node Exporter), network plugins.

**DaemonSet manifest** ‚Äî `daemonset.yml`

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-daemonsets
  namespace: nginx
spec:
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

**Commands**

```bash
kubectl apply -f daemonset.yml
kubectl get pods -n nginx
kubectl get pods -n nginx -o wide    # verify one-per-node
kubectl delete -f daemonset.yml
```

**Interview tip:** discuss node selectors, tolerations and when DaemonSet won't schedule (taints).

---

## Step 7 ‚Äî Jobs (theory + manifest)

### Theory

* **Job** runs one-off batch tasks until completion.
* **CronJob** schedules Jobs.

**Job manifest** ‚Äî `job.yml`

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: demo-job
  namespace: nginx
spec:
  completions: 1
  parallelism: 1
  template:
    metadata:
      labels:
        app: batch-task
    spec:
      containers:
      - name: batch-container
        image: busybox:latest
        command: ["sh", "-c", "echo hello Dosto ! && sleep 10"]
      restartPolicy: Never
```

**Commands**

```bash
kubectl apply -f job.yml
kubectl get job -n nginx
kubectl get pods -n nginx
kubectl logs pod/<job-pod-name> -n nginx
kubectl delete -f job.yml
```

**Interview tip:** discuss `backoffLimit`, `completions`, `parallelism`.

---

## Step 8 ‚Äî CronJob (theory + manifest)

### Theory

* **CronJob** schedules Jobs like cron (supports Kubernetes time format).
* Useful for backups, periodic reports, cleanup tasks.

**CronJob manifest** ‚Äî `cron-job.yml`

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: minute-backup
  namespace: nginx
spec:
  schedule: "* * * * *"  # every minute (example)
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: minute-backup
        spec:
          containers:
          - name: backup-container
            image: busybox
            command:
            - sh
            - -c
            - >
              echo "Backup Started" ;
              mkdir -p /backups &&
              mkdir -p /demo-data &&
              cp -r /demo-data /backups &&
              echo "Backup Completed" ;
            volumeMounts:
            - name: data-volume
              mountPath: /demo-data
            - name: backup-volume
              mountPath: /backups
          restartPolicy: OnFailure
          volumes:
          - name: data-volume
            hostPath:
              path: /demo-data
              type: DirectoryOrCreate
          - name: backup-volume
            hostPath:
              path: /backup
              type: DirectoryOrCreate
```

**Commands**

```bash
kubectl apply -f cron-job.yml
kubectl get cronjob -n nginx
kubectl get pods -n nginx
kubectl logs pod/<cronjob-pod-name> -n nginx
kubectl delete -f cron-job.yml
```

**Interview tip:** mention concurrencyPolicy and successfulJobsHistoryLimit / failedJobsHistoryLimit.

---

## Quick Cheatsheet ‚Äî Useful `kubectl` commands

```bash
kubectl get all -n <ns>                 # list resources in namespace
kubectl describe pod <pod> -n <ns>      # detailed pod info
kubectl logs <pod> -n <ns>              # get logs
kubectl port-forward pod/<pod> 8080:80  # local access to pod
kubectl apply -f <file>.yml             # apply manifest (create/update)
kubectl delete -f <file>.yml            # delete resource(s)
kubectl rollout status deployment/<name> -n <ns>  # check rollout
kubectl top pod                          # resource usage (requires metrics-server)
```

---

## Small theory clarifications to mention in interviews

* **Pod vs Container:** A Pod can hold 1+ containers sharing network & storage. Containers alone are runtime units; Pods are K8s units.
* **ReplicaSet vs Deployment:** ReplicaSet enforces replica count; Deployment manages ReplicaSet lifecycle and updates.
* **DaemonSet vs Deployment:** DaemonSet ‚Üí one pod per node; Deployment ‚Üí desired replicas across cluster.
* **StatefulSet:** use for stateful apps (stable network IDs, stable storage).
* **Services:** ClusterIP (internal), NodePort (host port mapping), LoadBalancer (cloud LB).
* **Ingress:** L7 HTTP routing, TLS termination. IngressController required (NGINX, Traefik).
* **ConfigMap vs Secret:** ConfigMap for non-sensitive config; Secret for sensitive data (base64 encoded). Use external secret managers in prod (Vault, AWS Secrets Manager).
* **RBAC:** Roles & RoleBindings (namespace) / ClusterRoles & ClusterRoleBindings (cluster-wide).
* **Storage:** PV and PVC abstractions; dynamic provisioners using CSI drivers.

---

## Extra: How to present this in an interview (phrasing)

* ‚ÄúI created multi-node test clusters using **kind**, used **kubeadm** to bootstrap VMs, and provisioned production clusters using **eksctl/Terraform**. I deployed NGINX using a Deployment + Service, performed rolling updates (`kubectl set image`), and used DaemonSets for node-level agents. For scheduled tasks I used CronJobs, and for batch I used Jobs. I also handled common Docker/Kubernetes environment issues such as Docker socket permissions and CPU resource limits.‚Äù

---


======================================================================

Natraj, **bahut accha detailed notes banaye ho**, but abhi raw format me hai.
**Maine pura content ko rearrange, clean, structured, interview-level, practical-level, and professional format me convert kar diya hai.**
Aap directly **GitHub Pages / DevOps Notes website / Notion / OneNote / PDF** me use kar sakte ho.

---

# ‚úÖ **KUBERNETES STORAGE + DEPLOYMENT + SERVICE + INGRESS

(Clean, Arranged, Interview-Level Notes)**

---

# üîπ **SECTION 1 ‚Äî Kubernetes Storage Concepts**

Kubernetes me storage ke 4 main components hote hai:

1Ô∏è‚É£ **Persistent Volume (PV)**
2Ô∏è‚É£ **Persistent Volume Claim (PVC)**
3Ô∏è‚É£ **Storage Class (SC)**
4Ô∏è‚É£ **Volume Mounts inside Pods**

Storage ka flow:

```
Node Storage ‚Üí PV ‚Üí PVC ‚Üí Pod Volume Mount
```

---

# üîπ **STEP 1 ‚Äî Create Persistent Volume (PV)**

**File: persistentVolume.yml**

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: local-pv
  namespace: nginx
spec:
  capacity:
    storage: 2Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: local-storage
  hostPath:
    path: /mnt/data
```

### Commands:

```bash
kubectl apply -f persistentVolume.yml
kubectl get pv
```

---

# üîπ **STEP 2 ‚Äî Create Persistent Volume Claim (PVC)**

**File: persistentVolumeClaim.yml**

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: local-pvc
  namespace: nginx
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: local-storage
```

### Commands:

```bash
kubectl apply -f persistentVolumeClaim.yml
kubectl get pvc -n nginx
```

üìå **Note**: PVC claim ho jaye to PV ka status **Bound** ho jata hai.

---

# üîπ **STEP 3 ‚Äî Deploy Nginx with Volume Mount**

**File: deployment.yml**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - mountPath: /var/www/html
          name: my-volume
      volumes:
      - name: my-volume
        persistentVolumeClaim:
          claimName: local-pvc
```

---

### ‚ùó **Common Error**

```
FailedScheduling: persistentvolumeclaim "local-pvc" not found
```

### üîß **Solution**

Namespaces PV/PVC me add karo:

```yaml
metadata:
  namespace: nginx
```

Then delete & recreate:

```bash
kubectl delete pvc/local-pvc -n nginx
kubectl delete pv/local-pv
kubectl apply -f persistentVolume.yml
kubectl apply -f persistentVolumeClaim.yml
```

---

# üîπ **STEP 4 ‚Äî Check Data Storage Location**

Pod ‚Üí Docker Container ‚Üí HostPath storage

Commands:

```bash
kubectl get pods -n nginx -o wide
kubectl get nodes
```

Container me enter:

```bash
docker exec -it <container-id> bash
cd /mnt/data/
```

Yehi aapka actual saved data hota hai.

---

# üîπ **STEP 5 ‚Äî Create Nginx Service**

**File: service.yml**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
  namespace: nginx
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP
```

Apply:

```bash
kubectl apply -f service.yml
kubectl get svc -n nginx
```

---

# üîπ **Expose Nginx using Port Forward**

```bash
kubectl port-forward service/nginx-service -n nginx 81:80 --address=0.0.0.0
```

---

# üü¶ SECTION 2 ‚Äî Deploy Real Django Notes App

---

### **STEP 1: Build Docker Image**

```bash
docker build -t notes-app-k8s .
```

### **STEP 2: Login & Push to Docker Hub**

```bash
docker login -u natrajwadhai13
docker tag notes-app-k8s:latest natrajwadhai13/notes-app-k8s:latest
docker push natrajwadhai13/notes-app-k8s:latest
```

---

### **Create Namespace**

**namespace.yml**

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: notes-app
```

---

### **Create Deployment**

**deployment.yml**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: notes-app-deployment
  namespace: notes-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: notes-app
  template:
    metadata:
      labels:
        app: notes-app
    spec:
      containers:
      - name: notes-app
        image: natrajwadhai13/notes-app-k8s:latest
        ports:
        - containerPort: 8000
```

---

### **Create Service**

**service.yml**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: notes-app-service
  namespace: notes-app
spec:
  selector:
    app: notes-app
  ports:
    - port: 8000
      targetPort: 8000
  type: ClusterIP
```

---

### Apply All

```bash
kubectl apply -f namespace.yml
kubectl apply -f deployment.yml
kubectl apply -f service.yml
```

### Port Forward

```bash
kubectl port-forward service/notes-app-service -n notes-app 8000:8000 --address=0.0.0.0
```

---

# üü¶ SECTION 3 ‚Äî Ingress Setup (Production Style)

---

### STEP 1 ‚Äî Install Ingress Controller

```bash
kubectl apply -f https://kind.sigs.k8s.io/examples/ingress/deploy-ingress-nginx.yaml
```

Check:

```bash
kubectl get pods -n ingress-nginx
kubectl get svc -n ingress-nginx
```

---

### STEP 2 ‚Äî Create Ingress Rule

**ingress.yml**

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nginx-notes-ingress
  namespace: nginx
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - http:
      paths:
      - pathType: Prefix
        path: /nginx
        backend:
          service:
            name: nginx-service
            port:
              number: 80
      - pathType: Prefix
        path: /
        backend:
          service:
            name: notes-app-service
            port:
              number: 8000
```

Apply:

```bash
kubectl apply -f ingress.yml
kubectl get ing -n nginx
```

---

### STEP 3 ‚Äî Expose Ingress to External IP

```bash
kubectl port-forward svc/ingress-nginx-controller -n ingress-nginx 8080:80 --address=0.0.0.0
```

Access:

```
http://<server-ip>:8080/nginx
http://<server-ip>:8080/
```

---

# üéØ **FINAL ‚Äì What You Can Say in Interview**

### ‚úî "I have set up complete Kubernetes storage & application deployment pipeline using:"

* PV, PVC, StorageClass
* Deployment with Volume Mount
* ClusterIP service
* Port-forward access
* Deployed Django Notes App on Kubernetes
* Pushed Docker image to private registry
* Ingress Controller + URL routing
* Worked on troubleshooting Pending Pods, PVC binding issues

======================================


 **StatefulSets Notes** 
 

---

# ‚úÖ **Kubernetes StatefulSets ‚Äì Clean & Improved Notes**

## **1. Stateless vs Stateful Applications**

### **Stateless Apps ‚Üí Use: Deployment / ReplicaSet / DaemonSet**

* No data dependency
* Every replica is identical
* Example: NGINX, frontend apps

### **Stateful Apps ‚Üí Use: StatefulSet**

* Each Pod needs **stable network identity**
* Each Pod needs **persistent storage**
* Example: MySQL, MongoDB, Cassandra, Redis

---

# ‚úîÔ∏è **2. Creating Namespace**

`namespace.yml`

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: mysql
```

Apply:

```bash
kubectl apply -f namespace.yml
```

---

# ‚úîÔ∏è **3. Headless Service for StatefulSet**

StatefulSet ALWAYS needs a **Headless Service** (ClusterIP=None).

`service.yml`

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mysql-service
  namespace: mysql
spec:
  clusterIP: None
  selector:
    app: mysql
  ports:
  - name: mysql
    port: 3306
    targetPort: 3306
```

Apply:

```bash
kubectl apply -f service.yml
```

---

# ‚úîÔ∏è **4. StatefulSet Definition**

`statefulset.yml`

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-statefulset
  namespace: mysql
spec:
  serviceName: mysql-service
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        ports:
        - containerPort: 3306
        env:
        - name: MYSQL_ROOT_PASSWORD
          value: root
        - name: MYSQL_DATABASE
          value: devops
        volumeMounts:
        - name: mysql-data
          mountPath: /var/lib/mysql
  volumeClaimTemplates:
  - metadata:
      name: mysql-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 1Gi
```

Apply:

```bash
kubectl apply -f statefulset.yml
```

---

# ‚úîÔ∏è **5. Verification Commands**

### **Check Pods**

```bash
kubectl get pods -n mysql
```

EXPECTED OUTPUT:

```
mysql-statefulset-0
mysql-statefulset-1
mysql-statefulset-2
```

### **Check PVs created automatically**

```bash
kubectl get pv
```

You will see 3 PVs created for 3 replicas.

### **Check Service**

```bash
kubectl get svc -n mysql
```

Output:

```
NAME            TYPE        CLUSTER-IP   PORT(S)
mysql-service   ClusterIP   None         3306/TCP
```

---

# ‚úîÔ∏è **6. Accessing MySQL In StatefulSet**

Get pod name:

```bash
kubectl get pods -n mysql
```

Exec into first pod:

```bash
kubectl exec -it mysql-statefulset-0 -n mysql -- bash
```

Login MySQL:

```bash
mysql -u root -p
# password: root
```

Check DB:

```sql
SHOW DATABASES;
```

You will see:

```
devops
mysql
sys
performance_schema
information_schema
```

---

# ‚úîÔ∏è **7. StatefulSet Unique Features (Interview Points)**

### ‚úÖ **1. Stable Network IDs**

Pods are named with **ordinal index**:

```
mysql-statefulset-0
mysql-statefulset-1
mysql-statefulset-2
```

### ‚úÖ **2. Stable Storage**

Deleting pods does NOT delete data.
Example:

```bash
kubectl delete pod mysql-statefulset-0 -n mysql
```

Kubernetes recreates:

```
mysql-statefulset-0  (same name, same PV)
```

### ‚úÖ **3. Ordered Deployment**

Pod creation order:

```
0 ‚Üí 1 ‚Üí 2
```

### ‚ùó **Deployments do NOT guarantee this**

---

# ‚úîÔ∏è **8. Deleting StatefulSet Completely**

StatefulSet:

```bash
kubectl delete -f statefulset.yml
```

Headless Service:

```bash
kubectl delete -f service.yml
```

Namespace:

```bash
kubectl delete ns mysql
```

PVs won't auto-delete because `ReclaimPolicy = Retain`.

Delete manually (optional):

```bash
kubectl delete pv <pv-name>
```

---

# üéØ **Final Note (Add in Interview):**

üëâ **StatefulSet = stable identity + stable storage + ordered scaling**
üëâ Used for **Databases** and **Distributed systems** (Kafka, RabbitMQ, Redis, MongoDB).
üëâ Always requires **Headless Service**.

